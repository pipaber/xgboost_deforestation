# Peru Deforestation Modeling (District-Year)
XGBoost model + SHAP explainability + scenario analysis + 2021–2024 observed-loss validation + API + tree export/plots


This repository builds and evaluates a district-year deforestation prediction pipeline for Peru. It includes:

- **Training**: XGBoost regression trained on `log1p(Def_ha)` (predicts hectares after `expm1`).
- **Explainability**: SHAP plots for global and local interpretation.
- **Scenario analysis**: deterministic “good/mild/bad” perturbations of drivers.
- **Mapping**: Peru district bubble maps (admin-3 bubbles; admin-2 boundaries) generated by scenario runs.
- **Observed forest loss**: curated district loss (2001–2024) and remaining forest 2024.
- **Hindcast 2021–2024**: scenario-based evaluation comparing model projections vs observed loss.
- **Quarto report**: renders a single HTML report including metrics and all images.
- **API**: serves deforestation predictions + marginal effects endpoints for feature deltas.

---

## Repository layout (high level)

### Data (in repo root)
- `deforestation_dataset_PERU_imputed_coca.csv` (training/inference dataset; `;` separated)
- `Bosque_y_perdida_de_bosques_por_Distrito_al_2024_curated.csv`
  - district forest loss by year (2001–2024, `*_ha`)
  - remaining forest: `BOSQUE AL 2024_ha`
- `DISTRITOS_inei_geogpsperu_suyopomalia.zip` (district geometry; used for mapping)
- `Bosque_NoBosque_Perdida_2001_2024_Raster/` (raster assets; optional)

### Models
- `models/xgb_timecv_v1/`
  - `bundle.joblib`
  - `feature_columns.json`
  - `model.json`
  - `metrics_report.json`
  - `trials_log.csv`
  - `test_predictions.csv`

### Reports
- `reports/shap/<run>/` — SHAP summary + dependence + waterfall plots
- `reports/scenarios/<run>/` — per-scenario CSVs and plots (including maps)
- `reports/forest_loss_trends/` — observed-loss trend plots (dept/province, 2021–2024 focus)
- `reports/hindcast_2021_2024/` — observed vs predicted evaluation for 2021–2024
- `reports/quarto/deforestation_report.qmd` — Quarto report source (renders HTML)

### Source code (scripts)
- `src/deforestation/train_xgb_timecv.py` — rolling/expanding window time CV tuning (recommended)
- `src/deforestation/explain_shap.py` — generate SHAP plots
- `src/deforestation/run_scenarios.py` — baseline-year scenarios + plots + bubble maps
- `src/deforestation/analysis/forest_loss_trends.py` — plots observed loss trends from curated CSV
- `src/deforestation/analysis/hindcast_2021_2024.py` — scenario-based hindcast vs observed 2021–2024
- `src/deforestation/api.py` — prediction API with marginal effects endpoints

---

## Environment / dependencies

This project uses `uv` for Python dependency management (`pyproject.toml` + `uv.lock`).

### Install / run
- Install deps:
  - `uv sync` (or `uv add <package>` if missing)
- Run scripts:
  - `uv run python <script> ...`

### SHAP compatibility
SHAP uses `numba`, which requires **NumPy <= 2.3.x**. If you see:

> ImportError: Numba needs NumPy 2.3 or less

Fix with:
- `uv add "numpy<2.4"`

---

## Model definition

### Target
- `Def_ha` = deforestation area (hectares)

### Target transform
Training is done in log-space:
- `y_train = log1p(Def_ha)`
Predictions are returned in hectares:
- `pred_ha = expm1(pred_log)`

---

## Training (recommended): rolling/expanding time CV

Script:
- `src/deforestation/train_xgb_timecv.py`

Why:
- avoids leakage and “overfitting a single validation window”
- selects hyperparameters that generalize across multiple future-like folds

Example (CPU):
```
uv run python src/deforestation/train_xgb_timecv.py \
  --data deforestation_dataset_PERU_imputed_coca.csv \
  --sep ';' \
  --trials 200 \
  --seed 42 \
  --outdir models \
  --run-name xgb_timecv_v1 \
  --device cpu
```

Artifacts saved under `models/<run-name>/`:
- `bundle.joblib` (model + schema + config)
- `feature_columns.json`
- `metrics_report.json`
- `model.json`
- `trials_log.csv`
- `test_predictions.csv`

---

## Explainability (SHAP)

Script:
- `src/deforestation/explain_shap.py`

Example:
```
uv run python src/deforestation/explain_shap.py \
  --bundle models/xgb_timecv_v1/bundle.joblib \
  --data deforestation_dataset_PERU_imputed_coca.csv \
  --sep ';' \
  --split test \
  --out reports/shap/xgb_timecv_v1 \
  --topk 15
```

Outputs (under `reports/shap/<run>/`):
- `shap_summary_beeswarm.png`
- `shap_summary_bar.png`
- `shap_dependence_*.png`
- `shap_waterfall_example.png`
- `shap_mean_abs.csv`
- `top_features.txt`
- `shap_run_metadata.json`

How to interpret:
- Beeswarm: direction + distribution of effects (per row)
- Bar: global importance by mean(|SHAP|)
- Waterfall: local explanation for one example row
- Dependence: nonlinear relationships and interaction hints

---

## Scenario analysis + mapping

Script:
- `src/deforestation/run_scenarios.py`

Scenario config:
- `scenarios/scenarios.yaml`

What it does:
- selects a baseline slice (default `YEAR=2020`)
- applies deterministic transforms (good/mild/bad)
- predicts baseline and scenario
- computes deltas
- writes per-district and aggregated outputs
- generates plots and bubble maps

Example:
```
uv run python src/deforestation/run_scenarios.py \
  --bundle models/xgb_timecv_v1/bundle.joblib \
  --data deforestation_dataset_PERU_imputed_coca.csv \
  --sep ';' \
  --scenarios scenarios/scenarios.yaml \
  --out reports/scenarios/xgb_timecv_v1_baseline2020
```

Outputs under `reports/scenarios/<run>/`:
- `scenario_summary.json`
- `scenarios_total_pred_ha.png`
- `scenarios_total_delta_ha.png`
- per scenario folder (e.g., `good/`, `mild/`, `bad/`):
  - `*_district_results.csv`
  - `*_by_region.csv`, `*_by_department.csv`
  - `*_delta_hist.png`
  - `*_delta_by_region.png`
  - `*_top20_delta.png`
  - `*_bubblemap_pred_size_delta_color.png`
    - bubbles at district centroids
    - bubble size = predicted deforestation (ha)
    - bubble color = delta vs baseline (ha)
    - admin-2 boundaries derived from district polygons

---

## Observed forest loss (2001–2024): trend plots

Observed loss input:
- `Bosque_y_perdida_de_bosques_por_Distrito_al_2024_curated.csv`

Script:
- `src/deforestation/analysis/forest_loss_trends.py`

Run:
```
uv run python src/deforestation/analysis/forest_loss_trends.py \
  --csv Bosque_y_perdida_de_bosques_por_Distrito_al_2024_curated.csv \
  --out reports/forest_loss_trends \
  --top-provinces 20
```

Produces:
- department trends (2001–2024 and 2021–2024)
- province top-N trends
- remaining forest 2024 plots
- long-format CSVs for reuse

---

## Hindcast evaluation (2021–2024): predicted vs observed

Goal:
Compare observed forest loss (2021–2024) against model “projected” deforestation using:
- 2020 covariate baseline
- macro/scenario assumptions for missing 2021–2024 covariates
- official department coca totals (2020–2024)

Observed loss input:
- `Bosque_y_perdida_de_bosques_por_Distrito_al_2024_curated.csv`

Coca totals input (department totals 2020–2024):
- `data_external/coca_department_2020_2024.csv`

Script:
- `src/deforestation/analysis/hindcast_2021_2024.py`

Assumptions currently supported (transparent; editable):
- temperature delta based on NOAA global anomaly, with baseline 2020 = 1.02°C
- precipitation multiplicative factors (scenario-like) + region scaling
- population growth applied uniformly to district population features
- small multipliers for mining/infrastructure/agriculture (political uncertainty assumption)
- coca scaled to match official department totals 2020–2024 (district shares preserved)

Run:
```
uv run python src/deforestation/analysis/hindcast_2021_2024.py \
  --bundle models/xgb_timecv_v1/bundle.joblib \
  --data deforestation_dataset_PERU_imputed_coca.csv \
  --sep ';' \
  --loss Bosque_y_perdida_de_bosques_por_Distrito_al_2024_curated.csv \
  --out reports/hindcast_2021_2024 \
  --coca-dept-csv data_external/coca_department_2020_2024.csv
```

Outputs under `reports/hindcast_2021_2024/`:
- `observed_vs_pred_district_2021_2024.csv`
- `observed_vs_pred_by_department_2021_2024.csv`
- `observed_vs_pred_by_province_2021_2024.csv`
- `metrics_by_year.csv`
- `metrics_by_department.csv`
- plots:
  - `by_department_trends_observed_vs_pred.png`
  - `by_province_topN_trends_observed_vs_pred.png`
  - `scatter_observed_vs_pred_2021_2024.png`
  - `residuals_hist.png`
- `assumptions_used.json` (critical for reproducibility and transparency)

Interpretation:
This is a **scenario-based hindcast**, not a strict forecast, unless you provide true district-year covariates for 2021–2024. The goal is to test whether the model’s structure can track post-2020 observed trends under plausible covariate trajectories.

---

## Quarto report

Source:
- `reports/quarto/deforestation_report.qmd`

Render:
```
quarto render reports/quarto/deforestation_report.qmd
```

The report includes:
- training/test metrics (from `models/.../metrics_report.json`)
- all SHAP images (galleries)
- all scenario images (galleries)
- trend and hindcast plots (if referenced/added)

---

## API (prediction + marginal effects)

Script:
- `src/deforestation/api.py`

Purpose:
Serve deforestation predictions (ha) plus marginal-effects endpoints for feature deltas.
These are model what-if impacts, not causal effects.

### Run the API
From repo root:
```
uv run uvicorn deforestation.api:app --host 0.0.0.0 --port 8000
```

### Health check
```
curl http://localhost:8000/health
```

### Predict (default: hindcast mode)
The API is designed so the user does NOT need to provide every feature. The server:
- loads the baseline row for `UBIGEO` at `DEFORESTATION_BASELINE_YEAR` (default 2020)
- applies your numeric overrides (e.g., set YEAR=2024 and adjust Minería, Pobreza, pp, tmean, etc.)
- **if mode is `hindcast` (default), applies macro adjustments for YEAR > baseline**
- predicts hectares

Examples below use UBIGEO `100403` (HUANUCO / HUACAYBAMBA / COCHABAMBA, YEAR 2020) from
`deforestation_dataset_PERU_imputed_coca.csv`. Example values from that row:
`Coca_ha=8.136319`, `Infraestructura=0.81`, `Minería=0.0`, `pp=2307.476`, `tmean=15.78479`.

#### `/predict` request parameters
- `ubigeo` (required): district code (6-digit)
- `overrides` (optional): any feature overrides (YEAR, Minería, Pobreza, pp, tmean, etc.)
- `mode` (optional): `"hindcast"` (default) or `"baseline"`

#### Example request (hindcast for 2024)
```
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d "{
    \"ubigeo\": \"100403\",
    \"overrides\": {
      \"YEAR\": 2024
    },
    \"mode\": \"hindcast\"
  }"
```

#### Example request (baseline mode)
```
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d "{
    \"ubigeo\": \"100403\",
    \"overrides\": {
      \"YEAR\": 2020,
      \"Coca_ha\": 8.136319,
      \"Infraestructura\": 0.81,
      \"Minería\": 0.0,
      \"pp\": 2307.476,
      \"tmean\": 15.78479
    },
    \"mode\": \"baseline\"
  }"
```

### Aggregate predictions (departments or provinces)
Endpoint:
- `POST /predict/aggregate`

What it does:
- uses the full baseline slice (all districts at `DEFORESTATION_BASELINE_YEAR`)
- applies `overrides` globally to all districts
- applies `hindcast` macro adjustments if enabled (default) and `YEAR > baseline`
- predicts hectares for all districts and aggregates totals

#### `/predict/aggregate` request parameters
- `group_by` (required): `"department"` or `"province"`
- `overrides` (optional): global overrides applied to all districts (e.g., `{"YEAR": 2024}`)
- `mode` (optional): `"hindcast"` (default) or `"baseline"`

#### Example request: total predicted deforestation by department (hindcast 2024)
```
curl -X POST http://localhost:8000/predict/aggregate \
  -H "Content-Type: application/json" \
  -d "{
    \"group_by\": \"department\",
    \"overrides\": { \"YEAR\": 2024 },
    \"mode\": \"hindcast\"
  }"
```

#### Example request: total predicted deforestation by province (nested by department)
Response structure for `group_by="province"` is nested:
```
{
  "HUANUCO": {
    "HUACAYBAMBA": { "pred_ha": 1234.56 },
    "HUAMALIES": { "pred_ha": 456.78 }
  }
}
```

Request:
```
curl -X POST http://localhost:8000/predict/aggregate \
  -H "Content-Type: application/json" \
  -d "{
    \"group_by\": \"province\",
    \"overrides\": { \"YEAR\": 2024 },
    \"mode\": \"hindcast\"
  }"
```

### Marginal effects by admin level
Endpoints:
- `POST /marginal/department` (NOMBDEP)
- `POST /marginal/province` (NOMBPROB)
- `POST /marginal/district` (NOMBDIST)

These compute finite-difference deltas in predicted hectares for feature changes.

#### Request parameters
- `overrides` (optional): global overrides (e.g., `{"YEAR": 2024}`)
- `mode` (optional): `"hindcast"` (default) or `"baseline"`
- `features` (optional): list of feature names to compute
- `deltas` (optional): per-feature additive deltas in native units
- `default_delta` (optional): default additive delta for unspecified features (default 1.0)

#### Example request: marginal effects by department
```
curl -X POST http://localhost:8000/marginal/department \
  -H "Content-Type: application/json" \
  -d "{
    \"overrides\": { \"YEAR\": 2024 },
    \"features\": [\"Coca_ha\", \"Infraestructura\"],
    \"deltas\": { \"Coca_ha\": 10, \"Infraestructura\": 0.1 },
    \"mode\": \"hindcast\"
  }"
```

Response includes, per group:
- `baseline_ha`
- `effects[feature].delta_ha` (change in predicted ha)
- `effects[feature].delta_per_unit` (ha per unit)
- `effects[feature].new_ha` (predicted ha after delta)

Notes:
- `hindcast` applies the same macro-style adjustments used in `hindcast_2021_2024.py` (population growth, NOAA temperature delta, precipitation multipliers by region, and simple multipliers for mining/infrastructure/agriculture/coca).
- `baseline` uses raw baseline values + overrides only (no macro adjustments).
- **Years beyond 2024:** the current API has built-in assumptions for 2021-2024 only. For later years it will fall back to neutral factors unless you override values.
  - **Recommended (next step):** move hindcast assumptions to a YAML file (e.g., `scenarios/hindcast_assumptions.yaml`) and use a **carry-forward policy** so that if a year is missing, the API uses the last available year's factors instead of failing.
- The response includes:
  - `predictions_ha`: predicted deforestation in hectares (for `/predict`)
  - `total_pred_ha`: total predicted hectares across all districts (for `/predict/aggregate`)
  - `meta` including overrides + hindcast adjustments applied

### API vs hindcast scripts
- The **hindcast scripts** are batch evaluation comparing model vs observed 2021-2024 across all districts.
- The **API** is for interactive, per-district and aggregated "what-if" predictions with marginal effects.

The API now supports **hindcast mode by default**, which aligns better with post-2020 usage.

---

## Frontend dashboard (vanilla + D3)

The frontend lives in `frontend/` and uses the API for predictions and marginal effects.

### Run locally
Terminal 1 (API):
```
uv run uvicorn deforestation.api:app --host 0.0.0.0 --port 8000
```

Terminal 2 (static frontend):
```
cd frontend
uv run python -m http.server 5173
```

Open `http://localhost:5173`.

### Map data (choropleth)
The D3 choropleth expects GeoJSON files placed under `frontend/data/`:
- `frontend/data/peru_departments.geojson` with a `NOMBDEP` property
- `frontend/data/peru_provinces.geojson` with a `NOMBPROB` property

If these files are missing, the map shows a placeholder message.

Generate GeoJSON from the INEI districts shapefile:
```
uv run python scripts/make_geojson.py --districts-zip DISTRITOS_inei_geogpsperu_suyopomalia.zip
```

---
## Reproducibility checklist
When publishing results, record:
- bundle path (`models/.../bundle.joblib`)
- dataset version and separator
- scenario config (`scenarios/scenarios.yaml`)
- hindcast assumptions (`reports/hindcast_2021_2024/assumptions_used.json`)
- git commit hash

---

## GitHub publishing notes
Recommended to NOT commit:
- `.venv/` (large)
- Quarto render caches / intermediates (`reports/quarto/*_files`, etc.)

This repo includes a `.gitignore` that ignores the above by default.

If you include large geodata (shapefiles/rasters), consider Git LFS.

---

## Plot / export XGBoost trees (model interpretability)

XGBoost models are ensembles of many trees. Plotting all trees is usually not useful, but exporting a *handful* can help with technical auditing and communication.

Script:
- `src/deforestation/plot_tree.py`

Outputs (under the chosen output directory):
- `tree_<index>.txt` (always written)
- `tree_<index>.png` (if Graphviz `dot` is installed)
- `tree_<index>_PNG_FAILED.txt` (written if PNG rendering fails, with diagnostics)

### Export a standard handful (first, middle, last tree)
```
uv run python src/deforestation/plot_tree.py \
  --bundle models/xgb_timecv_v1/bundle.joblib \
  --handful \
  --out reports/trees
```

### Export specific tree indices
```
uv run python src/deforestation/plot_tree.py \
  --bundle models/xgb_timecv_v1/bundle.joblib \
  --trees 0,50,100 \
  --out reports/trees
```

### Export a deterministic random sample
```
uv run python src/deforestation/plot_tree.py \
  --bundle models/xgb_timecv_v1/bundle.joblib \
  --n-sample 10 \
  --seed 42 \
  --out reports/trees
```

### Notes
- PNG rendering requires Graphviz installed and `dot` on PATH.
  - Ubuntu/Debian: `sudo apt-get install graphviz`
- If PNG fails, check the generated `*_PNG_FAILED.txt` file for actionable diagnostics.
